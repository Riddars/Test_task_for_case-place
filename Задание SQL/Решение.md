## Задание 1: Заказы Магазина 1 с выручкой
```SQL
SELECT 
    product_directory.name_store AS "Название магазина",  
    orders_directory.nomenclature AS "Номенклатура",  
    orders_directory.date AS "Дата заказа",  
    orders_directory.price * orders_directory.quantity_product AS "Выручка"  
FROM   
    orders_directory  
JOIN   
    product_directory ON orders_directory.nomenclature = product_directory.nomenclature  
WHERE   
    product_directory.name_store = 'Магазин 1';
```

## Задание 2: Принты, не используемые в product_directory
```SQL
SELECT 
    print_directory.*
FROM 
    print_directory
LEFT JOIN 
    product_directory ON print_directory.print = product_directory.print
WHERE 
    product_directory.print IS NULL;
```

## Задание 3: Номенклатуры с обоими названиями принта
```SQL
SELECT 
    product_directory.nomenclature AS "Номенклатура",
    print_directory.print AS "Артикул принта",
    print_directory.name_print_1 AS "Название принта"
FROM 
    product_directory
JOIN 
    print_directory ON product_directory.print = print_directory.print
WHERE 
    print_directory.name_print_1 IS NOT NULL 
    AND print_directory.name_print_2 IS NOT NULL;
```


## Задание 4: Номенклатуры с остатками на Складе 1
```SQL
SELECT 
    product_directory.name_store AS "Название магазина",
    stocks_directory.nomenclature AS "Номенклатура",
    stocks_directory.warehouse AS "Название склада",
    stocks_directory.value_stocks AS "Количество остатков"
FROM 
    stocks_directory
JOIN 
    product_directory ON stocks_directory.nomenclature = product_directory.nomenclature
WHERE 
    stocks_directory.warehouse = 'Склад 1' 
    AND stocks_directory.date = '2024-10-18';
```

## Задание 5: Заказы, выручка и прибыль по датам для Code_1
```SQL
SELECT 
    product_directory.barcode AS "Штрихкод товара",
    orders_directory.date AS "Дата",
    COUNT(orders_directory.nomenclature) AS "Количество заказов",
    SUM(orders_directory.price * orders_directory.quantity_product) AS "Выручка",
    SUM(orders_directory.price * orders_directory.quantity_product) * 0.95 AS "Прибыль с учетом налога"
FROM 
    orders_directory
JOIN 
    product_directory ON orders_directory.nomenclature = product_directory.nomenclature
WHERE 
    product_directory.barcode = 'Code_1'
GROUP BY 
    product_directory.barcode, orders_directory.date;
```

## Задание 6: 
### 1. Самый продаваемый принт
```SQL
SELECT 
    product_directory.print AS "Артикул принта",
    print_directory.name_print_1 AS "Название принта №1",
    SUM(orders_directory.quantity_product) AS "Количество продаж"
FROM 
    orders_directory
JOIN 
    product_directory ON orders_directory.nomenclature = product_directory.nomenclature
JOIN 
    print_directory ON product_directory.print = print_directory.print
GROUP BY 
    product_directory.print, print_directory.name_print_1
ORDER BY 
    SUM(orders_directory.quantity_product) DESC
LIMIT 1;
```

### 2. Триггер для логирования DDL действий
```SQL
CREATE TABLE ddl_log (
    id SERIAL PRIMARY KEY,
    event_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    schema_name TEXT,
    object_name TEXT,
    operation TEXT,
    username TEXT
);

CREATE FUNCTION log_ddl_changes() RETURNS event_trigger AS $$
BEGIN
    INSERT INTO ddl_log (schema_name, object_name, operation, username)
    SELECT 
        object_schema,
        object_identity,
        tg_tag,
        current_user
    FROM pg_event_trigger_ddl_commands();
EXCEPTION 
    WHEN OTHERS THEN
        RAISE NOTICE 'Ошибка логирования: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

CREATE EVENT TRIGGER ddl_trigger ON ddl_command_end
EXECUTE FUNCTION log_ddl_changes();
```

### 3. Триггер для логирования изменений product_directory
```SQL
CREATE TABLE product_log (
    id SERIAL PRIMARY KEY,
    change_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    operation TEXT,
    nomenclature TEXT,
    old_values JSONB,
    new_values JSONB,
    user_name TEXT
);

CREATE FUNCTION log_product_updates() RETURNS TRIGGER AS $$
BEGIN
    INSERT INTO product_log (operation, nomenclature, old_values, new_values, user_name)
    VALUES (
        TG_OP,
        NEW.nomenclature,
        row_to_json(OLD),
        row_to_json(NEW),
        current_user
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER product_update_trigger
AFTER UPDATE ON product_directory
FOR EACH ROW EXECUTE FUNCTION log_product_updates();
```

### 4. Создание БД и пользователей с разными правами
```SQL
CREATE DATABASE company_db;
\c company_db

CREATE SCHEMA business;

CREATE USER admin_user WITH PASSWORD 'admin123';
GRANT ALL ON SCHEMA business TO admin_user;
GRANT ALL ON ALL TABLES IN SCHEMA business TO admin_user;
GRANT ALL ON ALL SEQUENCES IN SCHEMA business TO admin_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA business GRANT ALL ON TABLES TO admin_user;

CREATE USER read_user WITH PASSWORD 'read123';
GRANT USAGE ON SCHEMA business TO read_user;
GRANT SELECT ON ALL TABLES IN SCHEMA business TO read_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA business GRANT SELECT ON TABLES TO read_user;
```


### 5. Ответы на вопросы:
**Какие индексы могут улучшить выполнение запроса?**  
Для нашего запроса, который ищет заказы за последний месяц, нужно создать обычный индекс по дате заказа:
```SQL
CREATE INDEX idx_orders_date ON orders(order_date);
```

**Как можно проверить, что индекс действительно улучшил производительность?**  
Самый простой способ - проверить время выполнения до и после. Запустить команду EXPLAIN ANALYZE перед запросом и посмотреть время выполнения, потом создать индекс и снова запустить EXPLAIN ANALYZE и сравнить время

**Как влияет VACUUM ANALYZE на производительность этого запроса?**  
```SQL
SELECT * FROM orders WHERE order_date >= CURRENT_DATE - INTERVAL'1 month';
```
VACUUM ANALYZE не особо поможет ускорить такой запрос. Конечно, он обновит статистику, но это не то, что реально нужно здесь  
Основная проблема запроса - он ищет записи за последний месяц без индекса. Просто создаём индекс по полю order_date  
VACUUM ANALYZE больше помогает в долгосрочной перспективе, поддерживает базу в порядке, обновляет статистику, чистит мусорные строки, но это профилактика, а не лечение медленных запросов  

**Какими ещё способами можно оптимизировать выполнение запросов к этой таблице?**  
1) Архивировать старые данные - перенести заказы старше года в отдельную историческую таблицу  
2) Выбирать только нужные столбцы вместо SELECT *  

